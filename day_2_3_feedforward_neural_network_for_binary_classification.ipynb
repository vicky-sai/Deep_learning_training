{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"day_2_3_feedforward_neural_network_for_binary_classification.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"uYGdSvZq0Jux","colab_type":"text"},"source":["Title: Feedforward Neural Network For Binary Classification    \n","Slug: feedforward_neural_network_for_binary_classification    \n","Summary: How to use Keras to train a feedforward neural network for binary classification in Python.   "]},{"cell_type":"markdown","metadata":{"id":"hdS1FJ3Y0Juz","colab_type":"text"},"source":["## Preliminaries"]},{"cell_type":"code","metadata":{"id":"m3xYtxFZ0Ju0","colab_type":"code","colab":{}},"source":["# Load libraries\n","import numpy as np\n","from keras.datasets import imdb\n","from keras.preprocessing.text import Tokenizer\n","from keras import models\n","from keras import layers\n","\n","# Set random seed\n","np.random.seed(0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jd-I_2200Ju-","colab_type":"text"},"source":["## Load Movie Review Data"]},{"cell_type":"code","metadata":{"id":"GYF0xUSv0Ju_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1598511908204,"user_tz":-330,"elapsed":11889,"user":{"displayName":"Sudhanshu Saxena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtLNR6bSzgfK2Cto1rNC4C71j5LZTfq3vL5ZB7wT4=s64","userId":"06805949978483919255"}},"outputId":"df09620f-77bf-423f-efbc-ad2a157ad0a8"},"source":["# Set the number of features we want\n","number_of_features = 1000\n","\n","# Load data and target vector from movie review data\n","(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\n","\n","# Convert movie review data to one-hot encoded feature matrix\n","tokenizer = Tokenizer(num_words=number_of_features)\n","train_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\n","test_features = tokenizer.sequences_to_matrix(test_data, mode='binary')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17465344/17464789 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vv_Y5dKjvEVn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":138},"executionInfo":{"status":"ok","timestamp":1598511931443,"user_tz":-330,"elapsed":2166,"user":{"displayName":"Sudhanshu Saxena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtLNR6bSzgfK2Cto1rNC4C71j5LZTfq3vL5ZB7wT4=s64","userId":"06805949978483919255"}},"outputId":"b9470c9d-413e-4614-df6c-b0e3db652de5"},"source":["train_features"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 1., 1., ..., 0., 0., 0.],\n","       [0., 1., 1., ..., 0., 0., 0.],\n","       [0., 1., 1., ..., 0., 0., 0.],\n","       ...,\n","       [0., 1., 1., ..., 0., 0., 0.],\n","       [0., 1., 1., ..., 0., 0., 0.],\n","       [0., 1., 1., ..., 0., 0., 0.]])"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"T1CpLCadu_Ax","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"status":"ok","timestamp":1598511915781,"user_tz":-330,"elapsed":2419,"user":{"displayName":"Sudhanshu Saxena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtLNR6bSzgfK2Cto1rNC4C71j5LZTfq3vL5ZB7wT4=s64","userId":"06805949978483919255"}},"outputId":"f2b3b3e1-ed94-443c-d6b8-b4856915c870"},"source":["train_data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([list([1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n","       list([1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 715, 8, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 775, 7, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 656, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 625, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n","       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 4, 86, 320, 35, 534, 19, 263, 2, 2, 4, 2, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 2, 43, 645, 662, 8, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 780, 8, 106, 14, 2, 2, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2, 51, 9, 170, 23, 595, 116, 595, 2, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n","       ...,\n","       list([1, 11, 6, 230, 245, 2, 9, 6, 2, 446, 2, 45, 2, 84, 2, 2, 21, 4, 912, 84, 2, 325, 725, 134, 2, 2, 84, 5, 36, 28, 57, 2, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 2, 14, 9, 31, 7, 4, 2, 2, 2, 2, 2, 18, 6, 20, 207, 110, 563, 12, 8, 2, 2, 8, 97, 6, 20, 53, 2, 74, 4, 460, 364, 2, 29, 270, 11, 960, 108, 45, 40, 29, 2, 395, 11, 6, 2, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 2, 11, 4, 2, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2, 234, 2, 2, 7, 496, 4, 139, 929, 2, 2, 2, 5, 2, 18, 4, 2, 2, 250, 11, 2, 2, 4, 2, 2, 747, 2, 372, 2, 2, 541, 2, 7, 4, 59, 2, 4, 2, 2]),\n","       list([1, 2, 2, 69, 72, 2, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 2, 51, 575, 32, 61, 369, 71, 66, 770, 12, 2, 75, 100, 2, 8, 4, 105, 37, 69, 147, 712, 75, 2, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 2, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 4, 719, 2, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n","       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2, 101, 405, 39, 14, 2, 4, 2, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 2, 2, 9, 24, 6, 78, 2, 17, 2, 2, 21, 27, 2, 2, 5, 2, 2, 92, 2, 4, 2, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 2, 4, 631, 2, 5, 2, 272, 191, 2, 6, 2, 8, 2, 2, 2, 544, 5, 383, 2, 848, 2, 2, 497, 2, 8, 2, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 2, 72, 7, 51, 6, 2, 22, 4, 204, 131, 9])],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"bxSGfO920JvD","colab_type":"text"},"source":["## Construct Neural Network Architecture"]},{"cell_type":"markdown","metadata":{"id":"pAU6rOTt0JvE","colab_type":"text"},"source":["Because this is a binary classification problem, one common choice is to use the sigmoid activation function in a one-unit output layer."]},{"cell_type":"code","metadata":{"id":"aQQv27k10JvF","colab_type":"code","colab":{}},"source":["# Start neural network\n","network = models.Sequential()\n","\n","# Add fully connected layer with a ReLU activation function\n","network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\n","\n","# Add fully connected layer with a ReLU activation function\n","network.add(layers.Dense(units=16, activation='relu'))\n","\n","# Add fully connected layer with a sigmoid activation function\n","network.add(layers.Dense(units=1, activation='sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y6cP5IA20JvJ","colab_type":"text"},"source":["## Compile Feedforward Neural Network"]},{"cell_type":"code","metadata":{"id":"ipSxLn2f0JvK","colab_type":"code","colab":{}},"source":["# Compile neural network\n","network.compile(loss='binary_crossentropy', # Cross-entropy\n","                optimizer='rmsprop', # Root Mean Square Propagation\n","                metrics=['accuracy']) # Accuracy performance metric"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9AxpwcFp0JvP","colab_type":"text"},"source":["## Train Feedforward Neural Network\n","\n","In Keras, we train our neural network using the `fit` method. There are six significant parameters to define. The first two parameters are the features and target vector of the training data. \n","\n","The `epochs` parameter defines how many epochs to use when training the data. `verbose` determines how much information is outputted during the training process, with `0` being no out, `1` outputting a progress bar, and `2` one log line per epoch. `batch_size` sets the number of observations to propagate through the network before updating the parameters.\n","\n","Finally, we held out a test set of data to use to evaluate the model. These test features and test target vector can be arguments of the `validation_data`, which will use them for evaluation. Alternatively, we could have used `validation_split` to define what fraction of the training data we want to hold out for evaluation.\n","\n","In scikit-learn `fit` method returned a trained model, however in Keras the `fit` method returns a `History` object containing the loss values and performance metrics at each epoch."]},{"cell_type":"code","metadata":{"id":"uz1NKJgU0JvQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598512251569,"user_tz":-330,"elapsed":39163,"user":{"displayName":"Sudhanshu Saxena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtLNR6bSzgfK2Cto1rNC4C71j5LZTfq3vL5ZB7wT4=s64","userId":"06805949978483919255"}},"outputId":"957ac96a-f251-4530-b4f3-38ae69b26f93"},"source":["# Train neural network\n","history = network.fit(train_features, # Features\n","                      train_target, # Target vector\n","                      epochs=50, # Number of epochs\n","                      verbose=1, # Print description after each epoch\n","                      batch_size=100, # Number of observations per batch\n","                      validation_data=(test_features, test_target)) # Data for evaluation"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","250/250 [==============================] - 1s 4ms/step - loss: 0.4196 - accuracy: 0.8122 - val_loss: 0.3419 - val_accuracy: 0.8550\n","Epoch 2/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3235 - accuracy: 0.8644 - val_loss: 0.3293 - val_accuracy: 0.8601\n","Epoch 3/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3130 - accuracy: 0.8694 - val_loss: 0.3392 - val_accuracy: 0.8544\n","Epoch 4/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3040 - accuracy: 0.8713 - val_loss: 0.3333 - val_accuracy: 0.8568\n","Epoch 5/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.2924 - accuracy: 0.8784 - val_loss: 0.3373 - val_accuracy: 0.8550\n","Epoch 6/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.2811 - accuracy: 0.8837 - val_loss: 0.3352 - val_accuracy: 0.8558\n","Epoch 7/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.2665 - accuracy: 0.8912 - val_loss: 0.3321 - val_accuracy: 0.8576\n","Epoch 8/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.2513 - accuracy: 0.8972 - val_loss: 0.3409 - val_accuracy: 0.8563\n","Epoch 9/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.2351 - accuracy: 0.9058 - val_loss: 0.3586 - val_accuracy: 0.8543\n","Epoch 10/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.2202 - accuracy: 0.9145 - val_loss: 0.3775 - val_accuracy: 0.8500\n","Epoch 11/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.2047 - accuracy: 0.9211 - val_loss: 0.3908 - val_accuracy: 0.8484\n","Epoch 12/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.1892 - accuracy: 0.9300 - val_loss: 0.4038 - val_accuracy: 0.8477\n","Epoch 13/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.1760 - accuracy: 0.9353 - val_loss: 0.4404 - val_accuracy: 0.8434\n","Epoch 14/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.1631 - accuracy: 0.9427 - val_loss: 0.4440 - val_accuracy: 0.8404\n","Epoch 15/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.1505 - accuracy: 0.9468 - val_loss: 0.5032 - val_accuracy: 0.8354\n","Epoch 16/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.1386 - accuracy: 0.9526 - val_loss: 0.5299 - val_accuracy: 0.8344\n","Epoch 17/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.1274 - accuracy: 0.9573 - val_loss: 0.5592 - val_accuracy: 0.8342\n","Epoch 18/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.1176 - accuracy: 0.9615 - val_loss: 0.5885 - val_accuracy: 0.8300\n","Epoch 19/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.1089 - accuracy: 0.9649 - val_loss: 0.6385 - val_accuracy: 0.8294\n","Epoch 20/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0989 - accuracy: 0.9682 - val_loss: 0.6944 - val_accuracy: 0.8264\n","Epoch 21/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0907 - accuracy: 0.9706 - val_loss: 0.7517 - val_accuracy: 0.8220\n","Epoch 22/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0831 - accuracy: 0.9744 - val_loss: 0.7932 - val_accuracy: 0.8251\n","Epoch 23/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0768 - accuracy: 0.9765 - val_loss: 0.8366 - val_accuracy: 0.8265\n","Epoch 24/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0702 - accuracy: 0.9784 - val_loss: 0.9294 - val_accuracy: 0.8210\n","Epoch 25/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0652 - accuracy: 0.9802 - val_loss: 1.0065 - val_accuracy: 0.8163\n","Epoch 26/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0593 - accuracy: 0.9822 - val_loss: 1.0249 - val_accuracy: 0.8204\n","Epoch 27/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0549 - accuracy: 0.9839 - val_loss: 1.1036 - val_accuracy: 0.8199\n","Epoch 28/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0501 - accuracy: 0.9851 - val_loss: 1.1657 - val_accuracy: 0.8197\n","Epoch 29/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0455 - accuracy: 0.9872 - val_loss: 1.1971 - val_accuracy: 0.8175\n","Epoch 30/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.9882 - val_loss: 1.4603 - val_accuracy: 0.8107\n","Epoch 31/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0388 - accuracy: 0.9888 - val_loss: 1.4876 - val_accuracy: 0.8094\n","Epoch 32/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0348 - accuracy: 0.9902 - val_loss: 1.4596 - val_accuracy: 0.8151\n","Epoch 33/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0341 - accuracy: 0.9902 - val_loss: 1.4893 - val_accuracy: 0.8151\n","Epoch 34/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0305 - accuracy: 0.9917 - val_loss: 1.5448 - val_accuracy: 0.8152\n","Epoch 35/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0299 - accuracy: 0.9928 - val_loss: 1.6443 - val_accuracy: 0.8123\n","Epoch 36/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0265 - accuracy: 0.9933 - val_loss: 1.6418 - val_accuracy: 0.8086\n","Epoch 37/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0243 - accuracy: 0.9936 - val_loss: 1.8075 - val_accuracy: 0.8101\n","Epoch 38/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0237 - accuracy: 0.9944 - val_loss: 1.8158 - val_accuracy: 0.8104\n","Epoch 39/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0195 - accuracy: 0.9955 - val_loss: 1.8682 - val_accuracy: 0.8113\n","Epoch 40/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0174 - accuracy: 0.9956 - val_loss: 1.9907 - val_accuracy: 0.8108\n","Epoch 41/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0173 - accuracy: 0.9964 - val_loss: 2.0379 - val_accuracy: 0.8090\n","Epoch 42/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0149 - accuracy: 0.9964 - val_loss: 2.1565 - val_accuracy: 0.8109\n","Epoch 43/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0174 - accuracy: 0.9962 - val_loss: 2.2233 - val_accuracy: 0.8084\n","Epoch 44/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 2.2368 - val_accuracy: 0.8102\n","Epoch 45/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0133 - accuracy: 0.9972 - val_loss: 2.2902 - val_accuracy: 0.8092\n","Epoch 46/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 2.3928 - val_accuracy: 0.8125\n","Epoch 47/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0137 - accuracy: 0.9973 - val_loss: 2.4051 - val_accuracy: 0.8103\n","Epoch 48/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 2.4517 - val_accuracy: 0.8093\n","Epoch 49/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0142 - accuracy: 0.9972 - val_loss: 2.5074 - val_accuracy: 0.8067\n","Epoch 50/50\n","250/250 [==============================] - 1s 3ms/step - loss: 0.0125 - accuracy: 0.9972 - val_loss: 2.5835 - val_accuracy: 0.8091\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UHZPirop0bw-","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}